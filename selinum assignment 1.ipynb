{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed11e899",
   "metadata": {},
   "source": [
    "WEB SCRAPING – ASSIGNMENT 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd101ed9",
   "metadata": {},
   "source": [
    "Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937ce18b",
   "metadata": {},
   "source": [
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0022fb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let import the required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "640eb405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ba744e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeableNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: webdriver-manager in c:\\users\\acer\\appdata\\roaming\\python\\python39\\site-packages (3.8.3)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from webdriver-manager) (4.64.0)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.27.1)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\acer\\appdata\\roaming\\python\\python39\\site-packages (from webdriver-manager) (0.21.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (1.26.9)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2021.10.8)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm->webdriver-manager) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9ca39a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "driver = webdriver.Chrome(ChromeDriverManager().install())\n",
    "\n",
    "driver.get(\"http://www.python.org\")\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9518c626",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver=webdriver.Chrome(r\"C:\\chrome driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6b221ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the naukri page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a70d54d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering designation as required in the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cdac89fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[1]/div/div/div/input\")\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "82b5b062",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering location as required in the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6d77afba",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cf5b7ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click on search button\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fb975bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[6]\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6165eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "336d7c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fc0c7d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1db3672b",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e084dfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "experience_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7d1a1902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "#let check the length of each required data\n",
    "\n",
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "81510d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the data into dataframe\n",
    "\n",
    "df=pd.DataFrame({'Job_title':job_title,'Job_location':job_location,'Company_name':company_name,'Experence_required':experience_required})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "82d12fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experence_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Chennai</td>\n",
       "      <td>Latentview</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Jar</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hiring For Data Analyst (DA)/ Team Lead (TL) -...</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>Cognizant</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Call For Clinical Data Analyst - Hyd/Bangalore...</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>Cognizant</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Payroll Transformation Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Arrow Electronics</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Payroll Transformation Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Arrow Electronics</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Master Data Management Business Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analytics and Interpretation Business Ana...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HR Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Hitachi Ltd.</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>ANZ</td>\n",
       "      <td>7-12 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0                                Senior Data Analyst   \n",
       "1                                       Data Analyst   \n",
       "2  Hiring For Data Analyst (DA)/ Team Lead (TL) -...   \n",
       "3  Call For Clinical Data Analyst - Hyd/Bangalore...   \n",
       "4                Payroll Transformation Data Analyst   \n",
       "5                Payroll Transformation Data Analyst   \n",
       "6            Master Data Management Business Analyst   \n",
       "7  Data Analytics and Interpretation Business Ana...   \n",
       "8                                    HR Data Analyst   \n",
       "9                                       Data Analyst   \n",
       "\n",
       "                                        Job_location       Company_name  \\\n",
       "0                       Bangalore/Bengaluru, Chennai         Latentview   \n",
       "1                                Bangalore/Bengaluru                Jar   \n",
       "2  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...          Cognizant   \n",
       "3  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...          Cognizant   \n",
       "4                                Bangalore/Bengaluru  Arrow Electronics   \n",
       "5                                Bangalore/Bengaluru  Arrow Electronics   \n",
       "6                                Bangalore/Bengaluru          Accenture   \n",
       "7                                Bangalore/Bengaluru          Accenture   \n",
       "8                                Bangalore/Bengaluru       Hitachi Ltd.   \n",
       "9                                Bangalore/Bengaluru                ANZ   \n",
       "\n",
       "  Experence_required  \n",
       "0            3-6 Yrs  \n",
       "1            0-4 Yrs  \n",
       "2            3-8 Yrs  \n",
       "3            6-9 Yrs  \n",
       "4            3-7 Yrs  \n",
       "5           5-10 Yrs  \n",
       "6            6-8 Yrs  \n",
       "7            6-8 Yrs  \n",
       "8            3-6 Yrs  \n",
       "9           7-12 Yrs  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing the data into dataframe\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeda5f1",
   "metadata": {},
   "source": [
    "Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You\n",
    "have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data.\n",
    "\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "78e45fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "32b51ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ba152c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver=webdriver.Chrome(r\"C:\\chrome driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "da213307",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the naukri page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3530af68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering designation as required in the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "38e929fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[1]/div/div/div/input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "56761ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering location as required in the question\n",
    "\n",
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6fa9d339",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click on search button\n",
    "\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[6]\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1c55fd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f5ac1b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Job title\n",
    "\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bf23ca17",
   "metadata": {},
   "outputs": [],
   "source": [
    "location_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "89a4c0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d89c41f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "#let check the length of each required data\n",
    "\n",
    "print(len(job_title),len(job_location),len(company_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8769e918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the data into dataframe\n",
    "\n",
    "df=pd.DataFrame({'Job_title':job_title,'Job_location':job_location,'Company_name':company_name})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "baa7629c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Manager</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mongodb Database Administrator, Maria DB or Ca...</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, P...</td>\n",
       "      <td>Mphasis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Analystics &amp; Modeling Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune</td>\n",
       "      <td>CitiusTech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, New Delhi, Pune, Gurgaon/...</td>\n",
       "      <td>ZS Associates</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, P...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, New Delhi, Chennai</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist: Artificial Intelligence</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>IBM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist - Computer Vision</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0                            Data Science Specialist   \n",
       "1                               Data Science Manager   \n",
       "2  Mongodb Database Administrator, Maria DB or Ca...   \n",
       "3                   Analystics & Modeling Specialist   \n",
       "4                   Assistant Manager - Data Science   \n",
       "5                                     Data Scientist   \n",
       "6                                     Data Scientist   \n",
       "7                              Senior Data Scientist   \n",
       "8            Data Scientist: Artificial Intelligence   \n",
       "9                   Data Scientist - Computer Vision   \n",
       "\n",
       "                                        Job_location             Company_name  \n",
       "0  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...                Accenture  \n",
       "1  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...                Accenture  \n",
       "2  Bangalore/Bengaluru, Hyderabad/Secunderabad, P...                  Mphasis  \n",
       "3  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...                Accenture  \n",
       "4                  Bangalore/Bengaluru, Mumbai, Pune               CitiusTech  \n",
       "5  Bangalore/Bengaluru, New Delhi, Pune, Gurgaon/...            ZS Associates  \n",
       "6  Bangalore/Bengaluru, Hyderabad/Secunderabad, P...            Tech Mahindra  \n",
       "7    Bangalore/Bengaluru, Mumbai, New Delhi, Chennai  Boston Consulting Group  \n",
       "8                                Bangalore/Bengaluru                      IBM  \n",
       "9                                Bangalore/Bengaluru                  Walmart  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b25da4",
   "metadata": {},
   "source": [
    "Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data.\n",
    "Note: All of the above steps have to be done in code. No step is to be done manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4f788379",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver=webdriver.Chrome(r\"C:\\chrome driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d94be326",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the naukri page on automated chrome browser\n",
    "driver.get(\"https://www.naukri.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "234123f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering designation as required in the question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "53da27e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[1]/div/div/div/input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6979c997",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering location as required in the question\n",
    "\n",
    "location=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input\")\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "05833a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Click on search button\n",
    "\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div[6]/div/div/div[6]\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "56f41e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying the salary filter\n",
    "\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[5]/div[2]/div[2]/label/p/span[1]\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "20789e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying the location filter\n",
    "\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div[4]/div/section[1]/div[2]/div[13]/div[2]/div[3]/label/p/span[1]\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8039097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title=[]\n",
    "job_location=[]\n",
    "company_name=[]\n",
    "experience_required=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "21c3ae2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Job title\n",
    "\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "133fa0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping Job location\n",
    "\n",
    "location_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "42a4522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping company name\n",
    "\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ef2c11b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrapping experience required\n",
    "\n",
    "experience_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "for i in experience_tags[0:10]:\n",
    "    experience=i.text\n",
    "    experience_required.append(experience)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "dd5a33ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "#let check the length of each required data\n",
    "\n",
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "46912bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing the data into dataframe\n",
    "\n",
    "df=pd.DataFrame({'Job_title':job_title,'Job_location':job_location,'Company_name':company_name,'Experence_required':experience_required})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c7b713fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Experence_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Nagpur, Bangalore/Bengaluru</td>\n",
       "      <td>GlobalLogic</td>\n",
       "      <td>8-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DigitalBCG GAMMA Data Scientist</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist / Chat-bot Developer</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru, Mumbai (All Ar...</td>\n",
       "      <td>Big Seo Buzz</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist - Engine Algorithm</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Activation Specialist - Adobe Target</td>\n",
       "      <td>Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...</td>\n",
       "      <td>Okda Solutions</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>IHS Markit</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Optum</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Noida(Sector-59 Noida)\\n(WFH during Covid)</td>\n",
       "      <td>R Systems International</td>\n",
       "      <td>7-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>NGI Ventures</td>\n",
       "      <td>0-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Intrics Solutions</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Job_title  \\\n",
       "0                             Data Scientist   \n",
       "1            DigitalBCG GAMMA Data Scientist   \n",
       "2        Data Scientist / Chat-bot Developer   \n",
       "3          Data Scientist - Engine Algorithm   \n",
       "4  Data Activation Specialist - Adobe Target   \n",
       "5                             Data Scientist   \n",
       "6                             Data Scientist   \n",
       "7                        Lead Data Scientist   \n",
       "8                             Data Scientist   \n",
       "9                             Data Scientist   \n",
       "\n",
       "                                        Job_location             Company_name  \\\n",
       "0                 Noida, Nagpur, Bangalore/Bengaluru              GlobalLogic   \n",
       "1                     New Delhi, Bangalore/Bengaluru  Boston Consulting Group   \n",
       "2  New Delhi, Bangalore/Bengaluru, Mumbai (All Ar...             Big Seo Buzz   \n",
       "3  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...             Primo Hiring   \n",
       "4  Delhi / NCR, Kolkata, Mumbai, Hyderabad/Secund...           Okda Solutions   \n",
       "5                                   Gurgaon/Gurugram               IHS Markit   \n",
       "6                                   Gurgaon/Gurugram                    Optum   \n",
       "7         Noida(Sector-59 Noida)\\n(WFH during Covid)  R Systems International   \n",
       "8                                              Noida             NGI Ventures   \n",
       "9                                              Noida        Intrics Solutions   \n",
       "\n",
       "  Experence_required  \n",
       "0           8-10 Yrs  \n",
       "1            2-5 Yrs  \n",
       "2            3-7 Yrs  \n",
       "3            1-3 Yrs  \n",
       "4           7-10 Yrs  \n",
       "5            3-6 Yrs  \n",
       "6            2-7 Yrs  \n",
       "7           7-10 Yrs  \n",
       "8            0-5 Yrs  \n",
       "9            3-8 Yrs  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd970375",
   "metadata": {},
   "source": [
    "Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and\n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the\n",
    "required data as usual.\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then\n",
    "click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100 sunglasses.\n",
    "Note: That all of the above steps have to be done by coding only and not manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "dc685b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5c210c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver=webdriver.Chrome(r\"C:\\chrome driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9097ae61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the flipkart page on automated chrome browser\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "721433f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search the “sunglasses” and click search button \n",
    "\n",
    "product=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "product.send_keys('Sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "33bea2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on the search button\n",
    "\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "search.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "365766bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand = []\n",
    "Product_Description = []\n",
    "Price= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a624a874",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    brand = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand:Brand.append(i.text)\n",
    "    \n",
    "    product_des = driver.find_elements(By.XPATH,\"//a[@class='IRpwTa']\")\n",
    "    for i in product_des:Product_Description.append(i.text)    \n",
    "    \n",
    "    price = driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "    for i in price:Price.append(i.text)\n",
    "    \n",
    "time.sleep(3)        \n",
    "        \n",
    "        \n",
    "nxt_button=driver.find_element(By.XPATH,\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "nxt_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1646b0c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(Product_Description),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "b742face",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Cat-eye S...</td>\n",
       "      <td>₹999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LIZA ANGEL</td>\n",
       "      <td>UV Protection, Polarized Rectangular Sunglasse...</td>\n",
       "      <td>₹261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>₹799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>UV Protection Round Sunglasses (54)</td>\n",
       "      <td>₹179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MODE</td>\n",
       "      <td>UV Protection Aviator Sunglasses (Free Size)</td>\n",
       "      <td>₹179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>Gradient, UV Protection Aviator Sunglasses (57)</td>\n",
       "      <td>₹272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (52)</td>\n",
       "      <td>₹246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>SHAAH COLLECTIONS</td>\n",
       "      <td>UV Protection Round Sunglasses (52)</td>\n",
       "      <td>₹179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Cat-eye S...</td>\n",
       "      <td>₹599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Wayfarer ...</td>\n",
       "      <td>₹999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Brand                                Product_Description Price\n",
       "0       VINCENT CHASE  by Lenskart Polarized, UV Protection Cat-eye S...  ₹999\n",
       "1          LIZA ANGEL  UV Protection, Polarized Rectangular Sunglasse...  ₹261\n",
       "2            Fastrack      UV Protection Wayfarer Sunglasses (Free Size)  ₹799\n",
       "3   SHAAH COLLECTIONS                UV Protection Round Sunglasses (54)  ₹179\n",
       "4                MODE       UV Protection Aviator Sunglasses (Free Size)  ₹179\n",
       "..                ...                                                ...   ...\n",
       "95             GANSTA    Gradient, UV Protection Aviator Sunglasses (57)  ₹272\n",
       "96             PIRASO          UV Protection Rectangular Sunglasses (52)  ₹246\n",
       "97  SHAAH COLLECTIONS                UV Protection Round Sunglasses (52)  ₹179\n",
       "98      VINCENT CHASE  by Lenskart Polarized, UV Protection Cat-eye S...  ₹599\n",
       "99      VINCENT CHASE  by Lenskart Polarized, UV Protection Wayfarer ...  ₹999\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets  make dataframe from the scraped data\n",
    "\n",
    "df = pd.DataFrame({'Brand': Brand,'Product_Description':Product_Description,'Price':Price})\n",
    "\n",
    "df.iloc[0:100,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e84757",
   "metadata": {},
   "source": [
    "Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.flipkart.com/\n",
    "2. Enter “iphone 11” in “Search” field .\n",
    "3. Then click the search button.\n",
    "You will reach to the below shown webpage .\n",
    "\n",
    "As shown in the above page you have to scrape the tick marked attributes.These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews.\n",
    "Note: All the steps required during scraping should be done through code only and not manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9fc7423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver=webdriver.Chrome(r\"C:\\chrome driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "03a3113f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Opening the flipkart page on automated chrome browser\n",
    "driver.get(\"https://www.flipkart.com/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "5b307607",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search the “iphone 11” and click search button \n",
    "\n",
    "product=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "product.send_keys('iphone 11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d30909d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button/svg\"}\n  (Session info: chrome=106.0.5249.62)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00471ED3+2236115]\n\tOrdinal0 [0x004092F1+1807089]\n\tOrdinal0 [0x003166FD+812797]\n\tOrdinal0 [0x003455DF+1005023]\n\tOrdinal0 [0x003457CB+1005515]\n\tOrdinal0 [0x00377632+1209906]\n\tOrdinal0 [0x00361AD4+1120980]\n\tOrdinal0 [0x003759E2+1202658]\n\tOrdinal0 [0x003618A6+1120422]\n\tOrdinal0 [0x0033A73D+960317]\n\tOrdinal0 [0x0033B71F+964383]\n\tGetHandleVerifier [0x0071E7E2+2743074]\n\tGetHandleVerifier [0x007108D4+2685972]\n\tGetHandleVerifier [0x00502BAA+532202]\n\tGetHandleVerifier [0x00501990+527568]\n\tOrdinal0 [0x0041080C+1837068]\n\tOrdinal0 [0x00414CD8+1854680]\n\tOrdinal0 [0x00414DC5+1854917]\n\tOrdinal0 [0x0041ED64+1895780]\n\tBaseThreadInitThunk [0x764DFA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77247B5E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77247B2E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Input \u001b[1;32mIn [132]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Click on search button\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m search\u001b[38;5;241m=\u001b[39m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button/svg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m search\u001b[38;5;241m.\u001b[39mclick()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:855\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    852\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    853\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m value\n\u001b[1;32m--> 855\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    856\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:428\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    426\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 428\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    429\u001b[0m     response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(\n\u001b[0;32m    430\u001b[0m         response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    431\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:243\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    242\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 243\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button/svg\"}\n  (Session info: chrome=106.0.5249.62)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00471ED3+2236115]\n\tOrdinal0 [0x004092F1+1807089]\n\tOrdinal0 [0x003166FD+812797]\n\tOrdinal0 [0x003455DF+1005023]\n\tOrdinal0 [0x003457CB+1005515]\n\tOrdinal0 [0x00377632+1209906]\n\tOrdinal0 [0x00361AD4+1120980]\n\tOrdinal0 [0x003759E2+1202658]\n\tOrdinal0 [0x003618A6+1120422]\n\tOrdinal0 [0x0033A73D+960317]\n\tOrdinal0 [0x0033B71F+964383]\n\tGetHandleVerifier [0x0071E7E2+2743074]\n\tGetHandleVerifier [0x007108D4+2685972]\n\tGetHandleVerifier [0x00502BAA+532202]\n\tGetHandleVerifier [0x00501990+527568]\n\tOrdinal0 [0x0041080C+1837068]\n\tOrdinal0 [0x00414CD8+1854680]\n\tOrdinal0 [0x00414DC5+1854917]\n\tOrdinal0 [0x0041ED64+1895780]\n\tBaseThreadInitThunk [0x764DFA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77247B5E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77247B2E+238]\n"
     ]
    }
   ],
   "source": [
    "#Click on search button\n",
    "\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button/svg\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "3647cdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#click on the \"APPLE iPhone 11 (White, 128 GB)\"\n",
    "\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "329a2dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rating = []\n",
    "Review_summary = []\n",
    "Full_review = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e20394e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    rating=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for i in rating:Rating.append(i.text)\n",
    "        \n",
    "    summary=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in summary:Review_summary.append(i.text)\n",
    "    \n",
    "    review=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for i in review:Full_review.append(i.text)           \n",
    "        \n",
    "next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "next_button.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3d7a9609",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Perfect product!',\n",
       " 'Terrific',\n",
       " 'Value-for-money',\n",
       " 'Classy product',\n",
       " 'Good quality product',\n",
       " 'Perfect product!',\n",
       " 'Fabulous!',\n",
       " 'Mind-blowing purchase',\n",
       " 'Perfect product!',\n",
       " 'Terrific',\n",
       " 'Value-for-money',\n",
       " 'Classy product',\n",
       " 'Good quality product',\n",
       " 'Perfect product!',\n",
       " 'Fabulous!',\n",
       " 'Mind-blowing purchase',\n",
       " 'Perfect product!',\n",
       " 'Terrific',\n",
       " 'Value-for-money',\n",
       " 'Classy product',\n",
       " 'Good quality product',\n",
       " 'Perfect product!',\n",
       " 'Fabulous!',\n",
       " 'Mind-blowing purchase',\n",
       " 'Perfect product!',\n",
       " 'Terrific',\n",
       " 'Value-for-money',\n",
       " 'Classy product',\n",
       " 'Good quality product',\n",
       " 'Perfect product!',\n",
       " 'Fabulous!',\n",
       " 'Mind-blowing purchase',\n",
       " 'Perfect product!',\n",
       " 'Terrific',\n",
       " 'Value-for-money',\n",
       " 'Classy product',\n",
       " 'Good quality product',\n",
       " 'Perfect product!',\n",
       " 'Fabulous!',\n",
       " 'Mind-blowing purchase',\n",
       " 'Perfect product!',\n",
       " 'Terrific',\n",
       " 'Value-for-money',\n",
       " 'Classy product',\n",
       " 'Good quality product',\n",
       " 'Perfect product!',\n",
       " 'Fabulous!',\n",
       " 'Mind-blowing purchase',\n",
       " 'Perfect product!',\n",
       " 'Terrific',\n",
       " 'Value-for-money',\n",
       " 'Classy product',\n",
       " 'Good quality product',\n",
       " 'Perfect product!',\n",
       " 'Fabulous!',\n",
       " 'Mind-blowing purchase',\n",
       " 'Perfect product!',\n",
       " 'Terrific',\n",
       " 'Value-for-money',\n",
       " 'Classy product',\n",
       " 'Good quality product',\n",
       " 'Perfect product!',\n",
       " 'Fabulous!',\n",
       " 'Mind-blowing purchase',\n",
       " 'Perfect product!',\n",
       " 'Terrific',\n",
       " 'Value-for-money',\n",
       " 'Classy product',\n",
       " 'Good quality product',\n",
       " 'Perfect product!',\n",
       " 'Fabulous!',\n",
       " 'Mind-blowing purchase',\n",
       " 'Perfect product!',\n",
       " 'Terrific',\n",
       " 'Value-for-money',\n",
       " 'Classy product',\n",
       " 'Good quality product',\n",
       " 'Perfect product!',\n",
       " 'Fabulous!',\n",
       " 'Mind-blowing purchase']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Review_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "d183db67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 80 80\n"
     ]
    }
   ],
   "source": [
    "print(len(Rating),len(Review_summary),len(Full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f61f0c10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review_summary</th>\n",
       "      <th>Full_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Perfect product!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Terrific</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>Value-for-money</td>\n",
       "      <td>Value-for-money</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Classy product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Good quality product</td>\n",
       "      <td>Good quality product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Classy product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>4</td>\n",
       "      <td>Good quality product</td>\n",
       "      <td>Good quality product</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Perfect product!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>5</td>\n",
       "      <td>Fabulous!</td>\n",
       "      <td>Fabulous!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>5</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "      <td>Mind-blowing purchase</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating         Review_summary            Full_review\n",
       "0       5       Perfect product!       Perfect product!\n",
       "1       5               Terrific               Terrific\n",
       "2       4        Value-for-money        Value-for-money\n",
       "3       5         Classy product         Classy product\n",
       "4       4   Good quality product   Good quality product\n",
       "..    ...                    ...                    ...\n",
       "75      5         Classy product         Classy product\n",
       "76      4   Good quality product   Good quality product\n",
       "77      5       Perfect product!       Perfect product!\n",
       "78      5              Fabulous!              Fabulous!\n",
       "79      5  Mind-blowing purchase  Mind-blowing purchase\n",
       "\n",
       "[80 rows x 3 columns]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lets  make dataframe from the scraped data\n",
    "\n",
    "df = pd.DataFrame({'Rating': Rating,'Review_summary':Review_summary,'Full_review':Full_review})\n",
    "\n",
    "df.iloc[0:100,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddaa81b9",
   "metadata": {},
   "source": [
    "Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the\n",
    "search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the tick marked attributes.\n",
    "Note: All the steps required during scraping should be done through code only and not manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ccb8da07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver=webdriver.Chrome(r\"C:\\chrome driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b9d39633",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the flipkart website on automated chrome window\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "858d21e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search the “sneakers” and click search button \n",
    "\n",
    "product=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "product.send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "eca2fd88",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/button\")\n",
    "search.click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8c6d1c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Brand = []\n",
    "Product_Description = []\n",
    "Price= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4cff7ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    product_des = driver.find_elements(By.XPATH,\"//div[@class='_2B099V']/a[1]\")\n",
    "    for i in product_des:Product_Description.append(i.text)\n",
    "   \n",
    "    brand = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand:Brand.append(i.text)\n",
    "      \n",
    "    price = driver.find_elements(By.XPATH,\"//div[@class='_30jeq3']\")\n",
    "    for i in price:Price.append(i.text)\n",
    "                   \n",
    "nxt_button=driver.find_element(By.XPATH,\"//a[@class='_1LKTO3']\")#scraping the list of buttons from the page\n",
    "nxt_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "02a6f114",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(Product_Description),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "50f59960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RED TAPE</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹1,499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Lightweight Pack Of 1 Trendy Sneakers Sneakers...</td>\n",
       "      <td>₹259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>World Wear Footwear</td>\n",
       "      <td>Latest Collection-1215 Stylish Casual Sports S...</td>\n",
       "      <td>₹298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>EZDEZARIO</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Rzisbo</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Deals4you</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>₹389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Shozie</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>₹478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>U.S. POLO ASSN.</td>\n",
       "      <td>TARANTIA Sneakers For Men</td>\n",
       "      <td>₹2,339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Brand                                Product_Description  \\\n",
       "0              RapidBox                                   Sneakers For Men   \n",
       "1              RapidBox                                   Sneakers For Men   \n",
       "2              RED TAPE                                   Sneakers For Men   \n",
       "3                BRUTON  Lightweight Pack Of 1 Trendy Sneakers Sneakers...   \n",
       "4   World Wear Footwear  Latest Collection-1215 Stylish Casual Sports S...   \n",
       "..                  ...                                                ...   \n",
       "95            EZDEZARIO                                   Sneakers For Men   \n",
       "96               Rzisbo                                   Sneakers For Men   \n",
       "97            Deals4you                                 Sneakers For Women   \n",
       "98               Shozie                                   Sneakers For Men   \n",
       "99      U.S. POLO ASSN.                          TARANTIA Sneakers For Men   \n",
       "\n",
       "     Price  \n",
       "0     ₹590  \n",
       "1     ₹610  \n",
       "2   ₹1,499  \n",
       "3     ₹259  \n",
       "4     ₹298  \n",
       "..     ...  \n",
       "95    ₹499  \n",
       "96    ₹549  \n",
       "97    ₹389  \n",
       "98    ₹478  \n",
       "99  ₹2,339  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.DataFrame()\n",
    "data['Brand']=Brand\n",
    "data['Product_Description']=Product_Description\n",
    "data['Price']=Price\n",
    "data.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667ecefc",
   "metadata": {},
   "source": [
    "Q7: Go to the link - https://www.myntra.com/shoes\n",
    "Set second Price filter and Color filter to “Black”, as shown in the below image.\n",
    "And then scrape First 100 shoes data you get. The data should include “Brand” of the shoes , Short Shoe\n",
    "description, price of the shoe as shown in the below image.\n",
    "Note: Applying the filter and scraping the data, everything should be done through code only and there\n",
    "should not be any manual step.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "bcb040ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver=webdriver.Chrome(r\"C:\\chrome driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7ab4c4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the myantra website on automated chrome window\n",
    "driver.get('https://www.myntra.com/shoes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "9c16754e",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_price=driver.find_element(By.XPATH,\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[6]/ul/li[1]\")\n",
    "filter_price.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "88570d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_black=driver.find_element(By.XPATH,\"/html/body/div[2]/div/div[1]/main/div[3]/div[1]/section/div/div[5]/ul/li[2]/label\")\n",
    "filter_black.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1cc0a75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Shoe_Brand = []\n",
    "Shoe_Description = []\n",
    "Shoe_Price= []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f731493f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    \n",
    "    brand = driver.find_elements(By.XPATH,'//h3[@class=\"product-brand\"]')\n",
    "    for i in brand:Shoe_Brand.append(i.text)\n",
    "        \n",
    "    product_des = driver.find_elements(By.XPATH,'//h4[@class=\"product-product\"]')\n",
    "    for i in product_des:Shoe_Description.append(i.text)\n",
    "        \n",
    "    price = driver.find_elements(By.XPATH,'//div[@class=\"product-price\"]')\n",
    "    for i in price:Shoe_Price.append(i.text)\n",
    "                   \n",
    "nxt_button=driver.find_element(By.XPATH,'//li[@class=\"pagination-next\"]') \n",
    "nxt_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "145d899d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 150 150\n"
     ]
    }
   ],
   "source": [
    "print(len(Shoe_Brand),len(Shoe_Description),len(Shoe_Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "5b5bb705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Shoe_Brand</th>\n",
       "      <th>Shoe_Description</th>\n",
       "      <th>Shoe_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men Go Walk Walking Shoes</td>\n",
       "      <td>Rs. 6374Rs. 7499(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men Leather Niteball Sneakers</td>\n",
       "      <td>Rs. 9599Rs. 11999(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Men Liberate Running Shoes</td>\n",
       "      <td>Rs. 9349Rs. 10999(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Men ZX 22 BOOST Sneakers</td>\n",
       "      <td>Rs. 10199Rs. 11999(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men GO WALK - TERRA Shoes</td>\n",
       "      <td>Rs. 8499Rs. 9999(15% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Puma</td>\n",
       "      <td>Cali Dream Leather Sneakers</td>\n",
       "      <td>Rs. 6399Rs. 7999(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ADIDAS Originals</td>\n",
       "      <td>Unisex Woven EQT93 Sandals</td>\n",
       "      <td>Rs. 7999Rs. 9999(20% OFF)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Skechers</td>\n",
       "      <td>Men Sky Vault Walking Shoes</td>\n",
       "      <td>Rs. 8999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ADIDAS</td>\n",
       "      <td>Women OZ-Takedown Running</td>\n",
       "      <td>Rs. 6999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Tommy Hilfiger</td>\n",
       "      <td>Men Solid Sneakers</td>\n",
       "      <td>Rs. 7499Rs. 9999(25% OFF)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Shoe_Brand               Shoe_Description  \\\n",
       "0           Skechers      Men Go Walk Walking Shoes   \n",
       "1   ADIDAS Originals  Men Leather Niteball Sneakers   \n",
       "2               Puma     Men Liberate Running Shoes   \n",
       "3   ADIDAS Originals       Men ZX 22 BOOST Sneakers   \n",
       "4           Skechers      Men GO WALK - TERRA Shoes   \n",
       "..               ...                            ...   \n",
       "95              Puma    Cali Dream Leather Sneakers   \n",
       "96  ADIDAS Originals     Unisex Woven EQT93 Sandals   \n",
       "97          Skechers    Men Sky Vault Walking Shoes   \n",
       "98            ADIDAS      Women OZ-Takedown Running   \n",
       "99    Tommy Hilfiger             Men Solid Sneakers   \n",
       "\n",
       "                     Shoe_Price  \n",
       "0     Rs. 6374Rs. 7499(15% OFF)  \n",
       "1    Rs. 9599Rs. 11999(20% OFF)  \n",
       "2    Rs. 9349Rs. 10999(15% OFF)  \n",
       "3   Rs. 10199Rs. 11999(15% OFF)  \n",
       "4     Rs. 8499Rs. 9999(15% OFF)  \n",
       "..                          ...  \n",
       "95    Rs. 6399Rs. 7999(20% OFF)  \n",
       "96    Rs. 7999Rs. 9999(20% OFF)  \n",
       "97                     Rs. 8999  \n",
       "98                     Rs. 6999  \n",
       "99    Rs. 7499Rs. 9999(25% OFF)  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.DataFrame()\n",
    "data['Shoe_Brand']=Shoe_Brand\n",
    "data['Shoe_Description']=Shoe_Description\n",
    "data['Shoe_Price']=Shoe_Price\n",
    "data.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d652440e",
   "metadata": {},
   "source": [
    "Q8: Go to webpage https://www.amazon.in/\n",
    "Enter “Laptop” in the search field and then click the search icon.\n",
    "Then set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "After setting the filters scrape first 10 laptops data. You have to scrape 3 attributesfor each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price\n",
    "Note: All the steps required during scraping should be done through code only and not manually.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "3cef0a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver=webdriver.Chrome(r\"C:\\chrome driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "90ca772f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the myantra website on automated chrome window\n",
    "driver.get('https://www.amazon.in')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "da3b0a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search the “Laptop” and click search button \n",
    "\n",
    "product=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input\")\n",
    "product.send_keys('Laptop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e5af9253",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search the “laptop” and click search button \n",
    "\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4edae716",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search the “laptop” and click search button \n",
    "\n",
    "filter_CPU=driver.find_element(By.XPATH,\"/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input\")\n",
    "filter_CPU.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "1700b0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Title = []\n",
    "Ratings = []\n",
    "Price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "f2bbfdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_title= driver.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base a-text-normal\"]')\n",
    "for i in product_title:Title.append(i.text)\n",
    "        \n",
    "product_rating = driver.find_elements(By.XPATH,'//span[@class=\"a-size-base s-underline-text\"]')\n",
    "for i in product_rating:Ratings.append(i.text)\n",
    "        \n",
    "product_price = driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "for i in product_price:Price.append(i.text)\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "84f30ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 24 28\n"
     ]
    }
   ],
   "source": [
    "print(len(Title),len(Ratings),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0a51d39b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (28) does not match length of index (24)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [164]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTitle\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mTitle\n\u001b[0;32m      3\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRatings\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mRatings\n\u001b[1;32m----> 4\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPrice\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mPrice\n\u001b[0;32m      5\u001b[0m data\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3655\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3653\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3654\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:3832\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3822\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3823\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3824\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   3825\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3830\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   3831\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3832\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3834\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   3835\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   3836\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   3837\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[0;32m   3838\u001b[0m     ):\n\u001b[0;32m   3839\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   3840\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4535\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   4534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 4535\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4536\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\common.py:557\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    554\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    555\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    556\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m--> 557\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    558\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    559\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    560\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    561\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    562\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (28) does not match length of index (24)"
     ]
    }
   ],
   "source": [
    "data=pd.DataFrame()\n",
    "data['Title']=Title\n",
    "data['Ratings']=Ratings\n",
    "data['Price']=Price\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c0cab2a",
   "metadata": {},
   "source": [
    "Q9: Write a python program to scrape data for first 10 job results for Data Scientist Designation in Noida\n",
    "location. You have to scrape company name, No. of days ago when job was posted, Rating of the company.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the Job option as shown in the image\n",
    "3. After reaching to the next webpage, In place of “Search by Designations, Companies, Skills” enter\n",
    "“Data Scientist” and click on search button.\n",
    "4. You will reach to the following web page click on location and in place of “Search location” enter\n",
    "“Noida” and select location “Noida”.\n",
    "5. Then scrape the data for the first 10 jobs results you get on the above shown page.\n",
    "6. Finally create a dataframe of the scraped data.\n",
    "Note: All the steps required during scraping should be done through code only and not manually.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "3eae9646",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver=webdriver.Chrome(r\"C:\\chrome driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "3dc3f3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the ambitionbox website on automated chrome window\n",
    "driver.get('https://www.ambitionbox.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "077592ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search the “Data scientist” and click search button \n",
    "\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div/div/div/div[1]/header/nav/ul/li[5]/a\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "1402061b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search the “Data scientist” and click search button \n",
    "\n",
    "designation=driver.find_element(By.XPATH,\"/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/div/span/input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4dda6f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search the “Data scientist” and click search button \n",
    "\n",
    "search=driver.find_element(By.XPATH,\"/html/body/div/div/div/div[2]/div[1]/div[1]/div/div/div/button/span\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "01036553",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_location=driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[1]/i')\n",
    "search_location.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d442dd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search the “Datascientist” and click search button \n",
    "\n",
    "enter_location=driver.find_element(By.XPATH,\"/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[2]/input\")\n",
    "enter_location.send_keys('Noida')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "94dff68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_Noida=driver.find_element(By.XPATH,'/html/body/div/div/div/div[2]/div[1]/div[2]/div[1]/div/div/div/div[2]/div[2]/div/div[3]/div[1]/div[1]/div/label')\n",
    "filter_Noida.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "3c3ac6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_name = []\n",
    "job_posted = []\n",
    "company_rating = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "21106270",
   "metadata": {},
   "outputs": [],
   "source": [
    "name= driver.find_elements(By.XPATH,'//p[@class=\"company body-medium\"]')\n",
    "for i in name:company_name.append(i.text)\n",
    "        \n",
    "posted = driver.find_elements(By.XPATH,'//span[@class=\"body-small-l\"]')\n",
    "for i in posted:job_posted.append(i.text)\n",
    "        \n",
    "rating = driver.find_elements(By.XPATH,'//span[@class=\"body-small\"]')\n",
    "for i in rating:company_rating.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "e4d13586",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '', '', '', '', '', '']"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posted=job_posted[::2]\n",
    "posted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a886df62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(company_name),len(posted),len(company_rating))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b3fdad09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_name</th>\n",
       "      <th>job_posted</th>\n",
       "      <th>company_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company_name job_posted company_rating\n",
       "0                                       \n",
       "1                                       \n",
       "2                                       \n",
       "3                                       \n",
       "4                                       \n",
       "5                                       \n",
       "6                                       \n",
       "7                                       \n",
       "8                                       \n",
       "9                                       "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.DataFrame()\n",
    "data['company_name']=company_name\n",
    "data['job_posted']=posted\n",
    "data['company_rating']=company_rating\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f1006d",
   "metadata": {},
   "source": [
    "Q10: Write a python program to scrape the salary data for Data Scientist designation.\n",
    "You have to scrape Company name, Number of salaries, Average salary, Minsalary, Max Salary.\n",
    "The above task will be, done as shown in the below steps:\n",
    "1. First get the webpage https://www.ambitionbox.com/\n",
    "2. Click on the salaries option as shown in the image.\n",
    "3. After reaching to the following webpage, In place of “Search Job Profile” enters “Data Scientist” and\n",
    "then click on “Data Scientist”.\n",
    "You have to scrape the data ticked in the above image.\n",
    "4. Scrape the data for the first 10 companies. Scrape the company name, total salary record, average\n",
    "salary, minimum salary, maximum salary, experience required.\n",
    "5. Store the data in a dataframe.\n",
    "Note: All the steps required during scraping should be done through code only and not manually\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "fee85c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let first connect to the driver\n",
    "driver=webdriver.Chrome(r\"C:\\chrome driver\\chromedriver.exe\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "64e32f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#opening the ambitionbox website on automated chrome window\n",
    "driver.get('https://www.ambitionbox.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "01d85186",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select \"salary\" option\n",
    "\n",
    "Click_on_salary=driver.find_element(By.XPATH,'/html/body/div/div/div/div[1]/header/nav/ul/li[3]/span')\n",
    "Click_on_salary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "061c99b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#select \"salary\" option\n",
    "\n",
    "Click_on_browse_salary=driver.find_element(By.XPATH,'/html/body/div/div/div/div[1]/header/nav/ul/li[3]/div/ul/li[1]/div/div[2]/a')\n",
    "Click_on_browse_salary.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "9da29970",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search the “Data Scientist”  \n",
    "\n",
    "designation=driver.find_element(By.XPATH,'/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/input')\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "7c678be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#search the “Data Scientist” and click search button \n",
    "\n",
    "search_button=driver.find_element(By.XPATH,'/html/body/div/div/div/main/section[1]/div[2]/div[1]/span/div/div/div[1]/div/div/p')\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "c7c5f929",
   "metadata": {},
   "outputs": [],
   "source": [
    "Company_name = []\n",
    "Total_Salary_Records = []\n",
    "Average_salary = []\n",
    "Minimum_salary = []\n",
    "Maximum_salary = []\n",
    "Experience_required = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "110087b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = driver.find_elements(By.XPATH,'//div[@class=\"company-info\"]')\n",
    "for i in name:Company_name.append(i.text.split(\"\\n\")[0])\n",
    "        \n",
    "record = driver.find_elements(By.XPATH,'//span[@class=\"datapoints\"]')\n",
    "for i in record:Total_Salary_Records.append(i.text)\n",
    "        \n",
    "avg_salary = driver.find_elements(By.XPATH,'//p[@class=\"averageCtc\"]')\n",
    "for i in avg_salary:Average_salary.append(i.text)\n",
    "\n",
    "min_salary = driver.find_elements(By.XPATH,'//div[@class=\"salary-values\"]')\n",
    "for i in min_salary:Minimum_salary.append(i.text.split(\"\\n\")[0])\n",
    "    \n",
    "max_salary = driver.find_elements(By.XPATH,'//div[@class=\"salary-values\"]')\n",
    "for i in max_salary:Maximum_salary.append(i.text.split(\"\\n\")[1])\n",
    "\n",
    "exp_req = driver.find_elements(By.XPATH,'//div[@class=\"sbold-list-header\"]')\n",
    "for i in exp_req:Experience_required.append(i.text.split(\"\\n\")[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "0d8959c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Walmart',\n",
       " 'Ab Inbev',\n",
       " 'Optum',\n",
       " 'ZS',\n",
       " 'Fractal Analytics',\n",
       " 'Sigmoid Analytics',\n",
       " 'Tiger Analytics',\n",
       " 'Legato Health Technologies',\n",
       " 'HSBC',\n",
       " 'Tredence']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Company_name=Company_name[0:10]\n",
    "Company_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "66fc905c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "#Checking length \n",
    "\n",
    "print(len(Company_name),len(Total_Salary_Records),len(Average_salary),len(Minimum_salary),len(Maximum_salary),len(Experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a31288bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company_name</th>\n",
       "      <th>Total_Salary_Records</th>\n",
       "      <th>Average_Salary</th>\n",
       "      <th>Minimum_Salary</th>\n",
       "      <th>Maximum_Salary</th>\n",
       "      <th>Experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Walmart</td>\n",
       "      <td>(based on 24 salaries)</td>\n",
       "      <td>₹ 32.2L</td>\n",
       "      <td>₹ 25.0L</td>\n",
       "      <td>₹ 45.0L</td>\n",
       "      <td>3-4 yrs experience (based on 24 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ab Inbev</td>\n",
       "      <td>(based on 59 salaries)</td>\n",
       "      <td>₹ 19.8L</td>\n",
       "      <td>₹ 15.0L</td>\n",
       "      <td>₹ 26.0L</td>\n",
       "      <td>2-4 yrs experience (based on 59 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Optum</td>\n",
       "      <td>(based on 49 salaries)</td>\n",
       "      <td>₹ 16.4L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 22.6L</td>\n",
       "      <td>2-4 yrs experience (based on 49 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ZS</td>\n",
       "      <td>(based on 35 salaries)</td>\n",
       "      <td>₹ 15.9L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 22.0L</td>\n",
       "      <td>1-2 yrs experience (based on 35 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>(based on 118 salaries)</td>\n",
       "      <td>₹ 15.5L</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 23.0L</td>\n",
       "      <td>2-4 yrs experience (based on 118 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sigmoid Analytics</td>\n",
       "      <td>(based on 10 salaries)</td>\n",
       "      <td>₹ 14.7L</td>\n",
       "      <td>₹ 12.7L</td>\n",
       "      <td>₹ 19.7L</td>\n",
       "      <td>1 yr experience (based on 10 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tiger Analytics</td>\n",
       "      <td>(based on 70 salaries)</td>\n",
       "      <td>₹ 14.6L</td>\n",
       "      <td>₹ 9.0L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>2-4 yrs experience (based on 70 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Legato Health Technologies</td>\n",
       "      <td>(based on 11 salaries)</td>\n",
       "      <td>₹ 14.5L</td>\n",
       "      <td>₹ 11.0L</td>\n",
       "      <td>₹ 20.0L</td>\n",
       "      <td>4 yrs experience (based on 11 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>HSBC</td>\n",
       "      <td>(based on 10 salaries)</td>\n",
       "      <td>₹ 14.0L</td>\n",
       "      <td>₹ 12.0L</td>\n",
       "      <td>₹ 18.0L</td>\n",
       "      <td>4 yrs experience (based on 10 salaries)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Tredence</td>\n",
       "      <td>(based on 14 salaries)</td>\n",
       "      <td>₹ 13.9L</td>\n",
       "      <td>₹ 8.8L</td>\n",
       "      <td>₹ 17.5L</td>\n",
       "      <td>3 yrs experience (based on 14 salaries)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Company_name     Total_Salary_Records Average_Salary  \\\n",
       "0                     Walmart   (based on 24 salaries)        ₹ 32.2L   \n",
       "1                    Ab Inbev   (based on 59 salaries)        ₹ 19.8L   \n",
       "2                       Optum   (based on 49 salaries)        ₹ 16.4L   \n",
       "3                          ZS   (based on 35 salaries)        ₹ 15.9L   \n",
       "4           Fractal Analytics  (based on 118 salaries)        ₹ 15.5L   \n",
       "5           Sigmoid Analytics   (based on 10 salaries)        ₹ 14.7L   \n",
       "6             Tiger Analytics   (based on 70 salaries)        ₹ 14.6L   \n",
       "7  Legato Health Technologies   (based on 11 salaries)        ₹ 14.5L   \n",
       "8                        HSBC   (based on 10 salaries)        ₹ 14.0L   \n",
       "9                    Tredence   (based on 14 salaries)        ₹ 13.9L   \n",
       "\n",
       "  Minimum_Salary Maximum_Salary                         Experience_required  \n",
       "0        ₹ 25.0L        ₹ 45.0L   3-4 yrs experience (based on 24 salaries)  \n",
       "1        ₹ 15.0L        ₹ 26.0L   2-4 yrs experience (based on 59 salaries)  \n",
       "2        ₹ 11.0L        ₹ 22.6L   2-4 yrs experience (based on 49 salaries)  \n",
       "3        ₹ 11.0L        ₹ 22.0L   1-2 yrs experience (based on 35 salaries)  \n",
       "4         ₹ 9.0L        ₹ 23.0L  2-4 yrs experience (based on 118 salaries)  \n",
       "5        ₹ 12.7L        ₹ 19.7L      1 yr experience (based on 10 salaries)  \n",
       "6         ₹ 9.0L        ₹ 20.0L   2-4 yrs experience (based on 70 salaries)  \n",
       "7        ₹ 11.0L        ₹ 20.0L     4 yrs experience (based on 11 salaries)  \n",
       "8        ₹ 12.0L        ₹ 18.0L     4 yrs experience (based on 10 salaries)  \n",
       "9         ₹ 8.8L        ₹ 17.5L     3 yrs experience (based on 14 salaries)  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create Dataframe\n",
    "\n",
    "df = pd.DataFrame({'Company_name':Company_name,'Total_Salary_Records':Total_Salary_Records,'Average_Salary':Average_salary,'Minimum_Salary':Minimum_salary,'Maximum_Salary':Maximum_salary,'Experience_required':Experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dec570d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
